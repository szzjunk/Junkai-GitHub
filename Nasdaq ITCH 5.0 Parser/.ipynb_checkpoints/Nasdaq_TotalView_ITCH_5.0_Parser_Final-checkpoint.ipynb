{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data Paths (Action Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Please set data_path to the location that contains 01302019.NASDAQ_ITCH50\n",
    "data_path = Path('D:/') \n",
    "itch_store = data_path / 'itch.h5'\n",
    "order_book_store = data_path / 'order_book.h5'\n",
    "vwap_store = data_path / 'vwap_store.h5'\n",
    "print('Setting data paths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITCH_filename='01302019.NASDAQ_ITCH50'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing libraries')\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from time import time\n",
    "from struct import unpack\n",
    "from collections import namedtuple, Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1: Extract Data from NASDAQ_ITCH50\n",
    "## ITCH Format Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Part1: Extract Data from NASDAQ_ITCH50')\n",
    "print('Setting ITCH Format')\n",
    "# System Event Codes – Daily\n",
    "event_codes = {'O': 'Start of Messages',\n",
    "               'S': 'Start of System Hours',\n",
    "               'Q': 'Start of Market Hours',\n",
    "               'M': 'End of Market Hours',\n",
    "               'E': 'End of System Hours',\n",
    "               'C': 'End of Messages'}\n",
    "\n",
    "encoding = {'primary_market_maker': {'Y': 1, 'N': 0},\n",
    "            'printable'           : {'Y': 1, 'N': 0},\n",
    "            'buy_sell_indicator'  : {'B': 1, 'S': -1},\n",
    "            'cross_type'          : {'O': 0, 'C': 1, 'H': 2},         # “O” = Opening Cross, “C” = Closing Cross, \n",
    "                                                                      # “H” = Cross for IPO and halted / paused securities\n",
    "            'imbalance_direction' : {'B': 0, 'S': 1, 'N': 0, 'O': -1}}\n",
    "                                                                      # “B” = buy imbalance, “S” = sell imbalance\n",
    "                                                                      # “N” = no imbalance, “O” = Insufficient orders to calculate\n",
    "\n",
    "# Formats Dictionary\n",
    "# It is used to assemble the format strings\n",
    "formats = { ('integer', 2): 'H',   # int of length 2 => format string 'H'\n",
    "            ('integer', 4): 'I',\n",
    "            ('integer', 6): '6s',  # int of length 6 => parse as string, convert later\n",
    "            ('integer', 8): 'Q',\n",
    "            ('alpha', 1)  : 's',\n",
    "            ('alpha', 2)  : '2s',\n",
    "            ('alpha', 4)  : '4s',\n",
    "            ('alpha', 8)  : '8s',\n",
    "            ('price_4', 4): 'I',\n",
    "            ('price_8', 8): 'Q', }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning message_types.xlsx and Creating Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing data format for Part 1')\n",
    "print('Cleaning message_types.xlsx')\n",
    "def clean_message_types(df):\n",
    "    # transfer all the columns' name into lower case and remove all the leading and trailing spaces\n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "    # remove all the leading and trailing spaces in the values\n",
    "    df.value = df.value.str.strip()\n",
    "    # clean all values in the name column \n",
    "    df.name = (df.name\n",
    "               .str.strip()\n",
    "               .str.lower()\n",
    "               .str.replace(' ', '_')\n",
    "               .str.replace('-', '_')\n",
    "               .str.replace('/', '_'))\n",
    "    # clean all values in the notes column \n",
    "    df.notes = df.notes.str.strip()\n",
    "    # add message type column\n",
    "    df['message_type'] = df.loc[df.name == 'message_type', 'value']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Message Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing message_types.xlsx')\n",
    "message_types = clean_message_types(pd.read_excel('message_types.xlsx', sheet_name='messages', encoding='latin1')\n",
    "                                    .sort_values('id').drop('id', axis=1))\n",
    "\n",
    "# Get Message Labels\n",
    "print('Creating message_labels')\n",
    "# extract the notes and message type columns that has value\n",
    "message_labels = (message_types.loc[:, ['message_type', 'notes']]\n",
    "                  .dropna()\n",
    "                  .rename(columns={'notes': 'name'}))\n",
    "\n",
    "# clean the notes column\n",
    "message_labels.name = (message_labels.name\n",
    "                       .str.lower()\n",
    "                       .str.replace('message', '')\n",
    "                       .str.replace('.', '')\n",
    "                       .str.strip().str.replace(' ', '_'))\n",
    "\n",
    "# message_labels.to_csv('message_labels.csv', index=False)\n",
    "\n",
    "# fill NA in the message_type column\n",
    "message_types.message_type = message_types.message_type.ffill()\n",
    "\n",
    "# remove the message type in the rows\n",
    "message_types = message_types[message_types.name != 'message_type']\n",
    "\n",
    "# clean the value column in the data frame\n",
    "message_types.value = (message_types.value\n",
    "                       .str.lower()\n",
    "                       .str.replace(' ', '_')\n",
    "                       .str.replace('(', '')\n",
    "                       .str.replace(')', ''))\n",
    "\n",
    "message_types.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get message specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating ITCH specs')\n",
    "# Get ITCH specs and create formatting (type, length) tuples\n",
    "specs = message_types\n",
    "specs['formats'] = specs[['value', 'length']].apply(tuple, axis=1).map(formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract alpha format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracting alpha format')\n",
    "# Extract formatting for alpha numerical fields\n",
    "alpha_fields = specs[specs.value == 'alpha'].set_index('name')\n",
    "# Groupby the message types\n",
    "alpha_msgs = alpha_fields.groupby('message_type')\n",
    "# Create the alpha format dictionary \n",
    "alpha_formats = {k: v.to_dict() for k, v in alpha_msgs.formats}\n",
    "# Create the alpha length dictionary\n",
    "alpha_length = {k: v.add(5).to_dict() for k, v in alpha_msgs.length}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate message classes as named tuples and format strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_fields, fstring = {}, {}\n",
    "for t, message in specs.groupby('message_type'):\n",
    "    message_fields[t] = namedtuple(typename=t, field_names=message.name.tolist())\n",
    "    fstring[t] = '>' + ''.join(message.formats.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Processing Data from ITCH 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_alpha(mtype, data):\n",
    "    \"\"\"Process byte strings of type alpha\"\"\"\n",
    "    for col in alpha_formats.get(mtype).keys():\n",
    "        if mtype != 'R' and col == 'stock':\n",
    "            data = data.drop(col, axis=1)\n",
    "            continue\n",
    "        data.loc[:, col] = data.loc[:, col].str.decode(\"utf-8\").str.strip()\n",
    "        if encoding.get(col):\n",
    "            data.loc[:, col] = data.loc[:, col].map(encoding.get(col))\n",
    "    return data\n",
    "\n",
    "def store_messages(m):\n",
    "    \"\"\"Handle occasional storing of all messages\"\"\"\n",
    "    with pd.HDFStore(itch_store) as store:\n",
    "        for mtype, data in m.items():\n",
    "            # convert to DataFrame\n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "            # parse timestamp info\n",
    "            data.timestamp = data.timestamp.apply(int.from_bytes, byteorder='big')\n",
    "            data.timestamp = pd.to_timedelta(data.timestamp)\n",
    "\n",
    "            # apply alpha formatting\n",
    "            if mtype in alpha_formats.keys():\n",
    "                data = format_alpha(mtype, data)\n",
    "\n",
    "            s = alpha_length.get(mtype)\n",
    "            if s:\n",
    "                s = {c: s.get(c) for c in data.columns}\n",
    "            dc = ['stock_locate']\n",
    "            if m == 'R':\n",
    "                dc.append('stock')\n",
    "            store.append(mtype,\n",
    "                         data,\n",
    "                         format='t',\n",
    "                         min_itemsize=20,  # set to a relative large value to deal with the length of data\n",
    "                         data_columns=dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from ITCH50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Extracting Data from ITCH50')\n",
    "print('About 30 mins...')\n",
    "start = time()\n",
    "messages = {}\n",
    "message_count = 0\n",
    "message_type_counter = Counter()\n",
    "data  = open(data_path / ITCH_filename, mode='rb')\n",
    "while True:\n",
    "\n",
    "    # Obtain the size of message in bytes\n",
    "    message_size = int.from_bytes(data.read(2), byteorder='big', signed=False)\n",
    "\n",
    "    # Get message type by reading first byte\n",
    "    message_type = data.read(1).decode('ascii')\n",
    "\n",
    "    # Create data structure to capture result\n",
    "    if not messages.get(message_type):\n",
    "        messages[message_type] = []\n",
    "\n",
    "    message_type_counter.update([message_type])\n",
    "\n",
    "    # Read & store the rest of one message\n",
    "    record = data.read(message_size - 1)\n",
    "    message = message_fields[message_type]._make(unpack(fstring[message_type], record))\n",
    "    messages[message_type].append(message)\n",
    "\n",
    "    # deal with system events\n",
    "    if message_type == 'S':\n",
    "        timestamp = int.from_bytes(message.timestamp, byteorder='big')\n",
    "        print('\\n', event_codes.get(message.event_code.decode('ascii'), 'Error'))\n",
    "        print('\\t{0}\\t{1:,.0f}'.format(timedelta(seconds=timestamp * 1e-9),\n",
    "                                     message_count))\n",
    "        if message.event_code.decode('ascii') == 'C':\n",
    "            store_messages(messages)\n",
    "            break\n",
    "\n",
    "    message_count += 1\n",
    "    if message_count % 2.5e7 == 0:\n",
    "        timestamp = int.from_bytes(message.timestamp, byteorder='big')\n",
    "        print('\\t{0}\\t{1:,.0f}\\t{2}'.format(timedelta(seconds=timestamp * 1e-9),\n",
    "                                            message_count,\n",
    "                                            timedelta(seconds=time() - start)))\n",
    "        store_messages(messages)\n",
    "        messages = {}\n",
    "\n",
    "print(timedelta(seconds=time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Build Order Book and Calculate VWAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '01302019'\n",
    "date = ITCH_filename.split('.')[0]\n",
    "date = '20190130'\n",
    "date = str(pd.to_datetime(date, format='%m%d%Y').date()).replace('-','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Building Order Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades(m):\n",
    "    \"\"\"Combine C, E, P and Q messages into trading records\"\"\"\n",
    "    trade_dict = {'executed_shares': 'shares', 'execution_price': 'price'}\n",
    "    cols = ['timestamp', 'executed_shares']\n",
    "    trades = pd.concat([m.loc[m.type == 'E', cols + ['price']].rename(columns=trade_dict),\n",
    "                        m.loc[m.type == 'C', cols + ['execution_price']].rename(columns=trade_dict),\n",
    "                        m.loc[m.type == 'P', ['timestamp', 'price', 'shares']],\n",
    "                        m.loc[m.type == 'Q', ['timestamp', 'price', 'shares']].assign(cross=1),\n",
    "                        ], sort=False).dropna(subset=['price']).fillna(0)\n",
    "    return trades.set_index('timestamp').sort_index().astype(int)\n",
    "\n",
    "def add_orders(orders, buysell, nlevels):\n",
    "    \"\"\"Add orders up to desired depth given by nlevels;\n",
    "        sell in ascending, buy in descending order\n",
    "    \"\"\"\n",
    "    new_order = []\n",
    "    items = sorted(orders.copy().items())\n",
    "    if buysell == 1:\n",
    "        items = reversed(items)  \n",
    "    for i, (p, s) in enumerate(items, 1):\n",
    "        new_order.append((p, s))\n",
    "        if i == nlevels:\n",
    "            break\n",
    "    return orders, new_order\n",
    "\n",
    "def save_orders(orders, append=False):\n",
    "    cols = ['price', 'shares']\n",
    "    for buysell, book in orders.items():\n",
    "        df = (pd.concat([pd.DataFrame(data=data,\n",
    "                                     columns=cols)\n",
    "                         .assign(timestamp=t) \n",
    "                         for t, data in book.items()]))\n",
    "        key = '{}/{}'.format(stock, order_dict[buysell])\n",
    "        df.loc[:, ['price', 'shares']] = df.loc[:, ['price', 'shares']].astype(int)\n",
    "        with pd.HDFStore(order_book_store) as store:\n",
    "            if append:\n",
    "                store.append(key, df.set_index('timestamp'), format='t')\n",
    "            else:\n",
    "                store.put(key, df.set_index('timestamp'))\n",
    "                \n",
    "def vwap(agg_trades):\n",
    "    vwap = agg_trades.apply(lambda x: np.average(x.price, weights=x.shares)).to_frame('vwap')\n",
    "    return vwap\n",
    "order_dict = {-1: 'sell', 1: 'buy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL 0.15% Completed\r"
     ]
    }
   ],
   "source": [
    "print('Building order book and calculating VWAP...')\n",
    "start = time()\n",
    "stock_list=list(set(pd.HDFStore(itch_store).select('R')['stock']))\n",
    "stock_list.sort()\n",
    "for i in range(len(stock_list)):\n",
    "    stock = stock_list[i]\n",
    "    print(stock+' '+str(round(i/float(len(stock_list))*100, 2))+'% Completed', end='\\r')\n",
    "    date = ITCH_filename.split('.')[0]\n",
    "    \n",
    "    # get_messages needs stock as an argument for extracting data from itch.h5\n",
    "    def get_messages(date, stock=stock):\n",
    "        \"\"\"Collect trading messages for given stock\"\"\"\n",
    "        with pd.HDFStore(itch_store) as store:\n",
    "            stock_locate = store.select('R')[store.select('R')['stock']==stock]['stock_locate']\n",
    "            target = 'stock_locate = stock_locate'\n",
    "\n",
    "            data = {}\n",
    "            # trading message types\n",
    "            messages = ['A', 'F', 'E', 'C', 'X', 'D', 'U', 'P', 'Q']\n",
    "            for m in messages:\n",
    "                data[m] = store.select(m, where=target).drop('stock_locate', axis=1).assign(type=m)\n",
    "\n",
    "        order_cols = ['order_reference_number', 'buy_sell_indicator', 'shares', 'price']\n",
    "        orders = pd.concat([data['A'], data['F']], sort=False, ignore_index=True).loc[:, order_cols]\n",
    "\n",
    "        for m in messages[2: -3]:\n",
    "            data[m] = data[m].merge(orders, how='left')\n",
    "\n",
    "        data['U'] = data['U'].merge(orders, how='left',\n",
    "                                    right_on='order_reference_number',\n",
    "                                    left_on='original_order_reference_number',\n",
    "                                    suffixes=['', '_replaced'])\n",
    "\n",
    "        data['Q'].rename(columns={'cross_price': 'price'}, inplace=True)\n",
    "        data['X']['shares'] = data['X']['cancelled_shares']\n",
    "        data['X'] = data['X'].dropna(subset=['price'])\n",
    "\n",
    "        data = pd.concat([data[m] for m in messages], ignore_index=True, sort=False)\n",
    "        data['date'] = pd.to_datetime(date, format='%m%d%Y')\n",
    "        data.timestamp = data['date'].add(data.timestamp)\n",
    "        data = data[data.printable != 0]\n",
    "\n",
    "        drop_cols = ['tracking_number', 'order_reference_number', 'original_order_reference_number',\n",
    "                     'cross_type', 'new_order_reference_number', 'attribution', 'match_number',\n",
    "                     'printable', 'date', 'cancelled_shares']\n",
    "        return data.drop(drop_cols, axis=1).sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Extracting messages for specific stock and date\n",
    "    messages = get_messages(date=date, stock=stock)\n",
    "    \n",
    "    # Storing messages into Orderbook\n",
    "    with pd.HDFStore(order_book_store) as store:\n",
    "        key = '{}/messages'.format(stock)\n",
    "        store.put(key, messages)\n",
    "    \n",
    "    # Combining C, E, P and Q messages into trading records and storing into order book\n",
    "    trades = get_trades(messages)\n",
    "    with pd.HDFStore(order_book_store) as store:\n",
    "        store.put('{}/trades'.format(stock), trades)\n",
    "    \n",
    "    order_book = {-1: {}, 1: {}}\n",
    "    current_orders = {-1: Counter(), 1: Counter()}\n",
    "    message_counter = Counter()\n",
    "    nlevels = 100\n",
    "\n",
    "\n",
    "    for message in messages.itertuples():\n",
    "        i = message[0]\n",
    "        if i % 1e5 == 0 and i > 0:\n",
    "            #print('{:,.0f}\\t\\t{}'.format(i, timedelta(seconds=time() - start)))\n",
    "            save_orders(order_book, append=True)\n",
    "            order_book = {-1: {}, 1: {}}\n",
    "            start = time()\n",
    "        if np.isnan(message.buy_sell_indicator):\n",
    "            continue\n",
    "        message_counter.update(message.type)\n",
    "\n",
    "        buysell = message.buy_sell_indicator\n",
    "        price, shares = None, None\n",
    "\n",
    "        if message.type in ['A', 'F', 'U']:\n",
    "            price = int(message.price)\n",
    "            shares = int(message.shares)\n",
    "\n",
    "            current_orders[buysell].update({price: shares})\n",
    "            current_orders[buysell], new_order = add_orders(current_orders[buysell], buysell, nlevels)\n",
    "            order_book[buysell][message.timestamp] = new_order\n",
    "\n",
    "        if message.type in ['E', 'C', 'X', 'D', 'U']:\n",
    "            if message.type == 'U':\n",
    "                if not np.isnan(message.shares_replaced):\n",
    "                    price = int(message.price_replaced)\n",
    "                    shares = -int(message.shares_replaced)\n",
    "            else:\n",
    "                if not np.isnan(message.price):\n",
    "                    price = int(message.price)\n",
    "                    shares = -int(message.shares)\n",
    "\n",
    "            if price is not None:\n",
    "                current_orders[buysell].update({price: shares})\n",
    "                if current_orders[buysell][price] <= 0:\n",
    "                    current_orders[buysell].pop(price)\n",
    "                current_orders[buysell], new_order = add_orders(current_orders[buysell], buysell, nlevels)\n",
    "                order_book[buysell][message.timestamp] = new_order\n",
    "    date = str(pd.to_datetime(date, format='%m%d%Y').date()).replace('-','')\n",
    "    with pd.HDFStore(itch_store) as store:\n",
    "        sys_events = store['S'].set_index('event_code').drop_duplicates()\n",
    "        sys_events.timestamp = sys_events.timestamp.add(pd.to_datetime(date)).dt.time\n",
    "        market_open = sys_events.loc['Q', 'timestamp']\n",
    "        market_close = sys_events.loc['M', 'timestamp']\n",
    "    with pd.HDFStore(order_book_store) as store:\n",
    "        trades = store['{}/trades'.format(stock)]\n",
    "\n",
    "    trades.price = trades.price.mul(1e-4)\n",
    "    trades = trades[trades.cross == 0]\n",
    "    trades = trades.between_time(market_open, market_close).drop('cross', axis=1)\n",
    "    trades_per_min = trades.shares.sum()/(60*7.5) # min per trading day\n",
    "    trades['cumul_vol'] = trades.shares.cumsum()\n",
    "    if trades.shape[0] == 0:\n",
    "        empty_output=pd.DataFrame([['Not Available', 'Not Available']], columns=['timestamp', 'vwap'])\n",
    "        with pd.HDFStore(vwap_store) as store:\n",
    "            key = stock\n",
    "            store.put(key, empty_output)\n",
    "        continue\n",
    "    df = trades.reset_index()\n",
    "    by_vol = df.groupby(df.cumul_vol.div(trades_per_min).round().astype(int))\n",
    "    vwap_time = pd.concat([by_vol.timestamp.last().to_frame('timestamp'), vwap(by_vol)], axis=1)\n",
    "    vwap_time.index.names=[''] \n",
    "    with pd.HDFStore(vwap_store) as store:\n",
    "        key = stock\n",
    "        store.put(key, vwap_time)\n",
    "print('The total time for creating VWAP is '+str(timedelta(seconds=time() - start))+'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.HDFStore(vwap_store).select('AAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list=list(set(pd.HDFStore(itch_store).select('R')['stock']))\n",
    "#stock_list.sort()\n",
    "stock_list=stock_list\n",
    "stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store=pd.HDFStore(vwap_store)\n",
    "#store.append(stock, vwap_time, append=True, format='t')\n",
    "with pd.HDFStore(vwap_store) as store:\n",
    "        key = '{}/messages'.format(stock)\n",
    "        store.put(key, vwap_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vwap_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = stock\n",
    "store=pd.HDFStore(vwap_store)\n",
    "store.put(key, vwap_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vwap_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(store, stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.HDFStore(vwap_store).select('ALL-G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
